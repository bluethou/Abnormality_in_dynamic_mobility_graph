{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import utils as u\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "#datasets\n",
    "import bitcoin_dl as bc\n",
    "import elliptic_temporal_dl as ell_temp\n",
    "import uc_irv_mess_dl as ucim\n",
    "import auto_syst_dl as aus\n",
    "import sbm_dl as sbm\n",
    "import reddit_dl as rdt\n",
    "\n",
    "\n",
    "#taskers\n",
    "import link_pred_tasker as lpt\n",
    "import edge_cls_tasker as ect\n",
    "import node_cls_tasker as nct\n",
    "\n",
    "#models\n",
    "import models as mls\n",
    "import egcn_h\n",
    "import egcn_o\n",
    "\n",
    "\n",
    "import splitter as sp\n",
    "import Cross_Entropy as ce\n",
    "\n",
    "import trainer as tr\n",
    "\n",
    "import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gimpuleumoe/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "with open(\"./experiments/COVID.yaml\", \"r\") as ymlfile:\n",
    "    cfg = yaml.load(ymlfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "globals().update(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def random_param_value(param, param_min, param_max, type='int'):\n",
    "\tif str(param) is None or str(param).lower()=='none':\n",
    "\t\tif type=='int':\n",
    "\t\t\treturn random.randrange(param_min, param_max+1)\n",
    "\t\telif type=='logscale':\n",
    "\t\t\tinterval=np.logspace(np.log10(param_min), np.log10(param_max), num=100)\n",
    "\t\t\treturn np.random.choice(interval,1)[0]\n",
    "\t\telse:\n",
    "\t\t\treturn random.uniform(param_min, param_max)\n",
    "\telse:\n",
    "\t\treturn param\n",
    "\n",
    "def build_random_hyper_params(args):\n",
    "\tif args.model == 'all':\n",
    "\t\tmodel_types = ['gcn', 'egcn_o', 'egcn_h', 'gruA', 'gruB','egcn','lstmA', 'lstmB']\n",
    "\t\targs.model=model_types[args.rank]\n",
    "\telif args.model == 'all_nogcn':\n",
    "\t\tmodel_types = ['egcn_o', 'egcn_h', 'gruA', 'gruB','egcn','lstmA', 'lstmB']\n",
    "\t\targs.model=model_types[args.rank]\n",
    "\telif args.model == 'all_noegcn3':\n",
    "\t\tmodel_types = ['gcn', 'egcn_h', 'gruA', 'gruB','egcn','lstmA', 'lstmB']\n",
    "\t\targs.model=model_types[args.rank]\n",
    "\telif args.model == 'all_nogruA':\n",
    "\t\tmodel_types = ['gcn', 'egcn_o', 'egcn_h', 'gruB','egcn','lstmA', 'lstmB']\n",
    "\t\targs.model=model_types[args.rank]\n",
    "\t\targs.model=model_types[args.rank]\n",
    "\telif args.model == 'saveembs':\n",
    "\t\tmodel_types = ['gcn', 'gcn', 'skipgcn', 'skipgcn']\n",
    "\t\targs.model=model_types[args.rank]\n",
    "\n",
    "\targs.learning_rate =random_param_value(args.learning_rate, args.learning_rate_min, args.learning_rate_max, type='logscale')\n",
    "\t# args.adj_mat_time_window = random_param_value(args.adj_mat_time_window, args.adj_mat_time_window_min, args.adj_mat_time_window_max, type='int')\n",
    "\n",
    "\tif args.model == 'gcn':\n",
    "\t\targs.num_hist_steps = 0\n",
    "\telse:\n",
    "\t\targs.num_hist_steps = random_param_value(args.num_hist_steps, args.num_hist_steps_min, args.num_hist_steps_max, type='int')\n",
    "\n",
    "\targs.gcn_parameters['feats_per_node'] =random_param_value(args.gcn_parameters['feats_per_node'], args.gcn_parameters['feats_per_node_min'], args.gcn_parameters['feats_per_node_max'], type='int')\n",
    "\targs.gcn_parameters['layer_1_feats'] =random_param_value(args.gcn_parameters['layer_1_feats'], args.gcn_parameters['layer_1_feats_min'], args.gcn_parameters['layer_1_feats_max'], type='int')\n",
    "\tif args.gcn_parameters['layer_2_feats_same_as_l1'] or args.gcn_parameters['layer_2_feats_same_as_l1'].lower()=='true':\n",
    "\t\targs.gcn_parameters['layer_2_feats'] = args.gcn_parameters['layer_1_feats']\n",
    "\telse:\n",
    "\t\targs.gcn_parameters['layer_2_feats'] =random_param_value(args.gcn_parameters['layer_2_feats'], args.gcn_parameters['layer_1_feats_min'], args.gcn_parameters['layer_1_feats_max'], type='int')\n",
    "\targs.gcn_parameters['lstm_l1_feats'] =random_param_value(args.gcn_parameters['lstm_l1_feats'], args.gcn_parameters['lstm_l1_feats_min'], args.gcn_parameters['lstm_l1_feats_max'], type='int')\n",
    "\tif args.gcn_parameters['lstm_l2_feats_same_as_l1'] or args.gcn_parameters['lstm_l2_feats_same_as_l1'].lower()=='true':\n",
    "\t\targs.gcn_parameters['lstm_l2_feats'] = args.gcn_parameters['lstm_l1_feats']\n",
    "\telse:\n",
    "\t\targs.gcn_parameters['lstm_l2_feats'] =random_param_value(args.gcn_parameters['lstm_l2_feats'], args.gcn_parameters['lstm_l1_feats_min'], args.gcn_parameters['lstm_l1_feats_max'], type='int')\n",
    "\targs.gcn_parameters['cls_feats']=random_param_value(args.gcn_parameters['cls_feats'], args.gcn_parameters['cls_feats_min'], args.gcn_parameters['cls_feats_max'], type='int')\n",
    "\treturn args\n",
    "\n",
    "def build_dataset(args):\n",
    "\tif args.data == 'bitcoinotc' or args.data == 'bitcoinalpha':\n",
    "\t\tif args.data == 'bitcoinotc':\n",
    "\t\t\targs.bitcoin_args = args.bitcoinotc_args\n",
    "\t\telif args.data == 'bitcoinalpha':\n",
    "\t\t\targs.bitcoin_args = args.bitcoinalpha_args\n",
    "\t\treturn bc.bitcoin_dataset(args)\n",
    "\telif args.data == 'aml_sim':\n",
    "\t\treturn aml.Aml_Dataset(args)\n",
    "\telif args.data == 'elliptic':\n",
    "\t\treturn ell.Elliptic_Dataset(args)\n",
    "\telif args.data == 'elliptic_temporal':\n",
    "\t\treturn ell_temp.Elliptic_Temporal_Dataset(args)\n",
    "\telif args.data == 'uc_irv_mess':\n",
    "\t\treturn ucim.Uc_Irvine_Message_Dataset(args)\n",
    "\telif args.data == 'dbg':\n",
    "\t\treturn dbg.dbg_dataset(args)\n",
    "\telif args.data == 'colored_graph':\n",
    "\t\treturn cg.Colored_Graph(args)\n",
    "\telif args.data == 'autonomous_syst':\n",
    "\t\treturn aus.Autonomous_Systems_Dataset(args)\n",
    "\telif args.data == 'reddit':\n",
    "\t\treturn rdt.Reddit_Dataset(args)\n",
    "\telif args.data.startswith('sbm'):\n",
    "\t\tif args.data == 'sbm20':\n",
    "\t\t\targs.sbm_args = args.sbm20_args\n",
    "\t\telif args.data == 'sbm50':\n",
    "\t\t\targs.sbm_args = args.sbm50_args\n",
    "\t\treturn sbm.sbm_dataset(args)\n",
    "\telse:\n",
    "\t\traise NotImplementedError('only arxiv has been implemented')\n",
    "\n",
    "def build_tasker(args,dataset):\n",
    "\tif args.task == 'link_pred':\n",
    "\t\treturn lpt.Link_Pred_Tasker(args,dataset)\n",
    "\telif args.task == 'edge_cls':\n",
    "\t\treturn ect.Edge_Cls_Tasker(args,dataset)\n",
    "\telif args.task == 'node_cls':\n",
    "\t\treturn nct.Node_Cls_Tasker(args,dataset)\n",
    "\telif args.task == 'static_node_cls':\n",
    "\t\treturn nct.Static_Node_Cls_Tasker(args,dataset)\n",
    "\n",
    "\telse:\n",
    "\t\traise NotImplementedError('still need to implement the other tasks')\n",
    "\n",
    "def build_gcn(args,tasker):\n",
    "\tgcn_args = u.Namespace(args.gcn_parameters)\n",
    "\tgcn_args.feats_per_node = tasker.feats_per_node\n",
    "\tif args.model == 'gcn':\n",
    "\t\treturn mls.Sp_GCN(gcn_args,activation = torch.nn.RReLU()).to(args.device)\n",
    "\telif args.model == 'skipgcn':\n",
    "\t\treturn mls.Sp_Skip_GCN(gcn_args,activation = torch.nn.RReLU()).to(args.device)\n",
    "\telif args.model == 'skipfeatsgcn':\n",
    "\t\treturn mls.Sp_Skip_NodeFeats_GCN(gcn_args,activation = torch.nn.RReLU()).to(args.device)\n",
    "\telse:\n",
    "\t\tassert args.num_hist_steps > 0, 'more than one step is necessary to train LSTM'\n",
    "\t\tif args.model == 'lstmA':\n",
    "\t\t\treturn mls.Sp_GCN_LSTM_A(gcn_args,activation = torch.nn.RReLU()).to(args.device)\n",
    "\t\telif args.model == 'gruA':\n",
    "\t\t\treturn mls.Sp_GCN_GRU_A(gcn_args,activation = torch.nn.RReLU()).to(args.device)\n",
    "\t\telif args.model == 'lstmB':\n",
    "\t\t\treturn mls.Sp_GCN_LSTM_B(gcn_args,activation = torch.nn.RReLU()).to(args.device)\n",
    "\t\telif args.model == 'gruB':\n",
    "\t\t\treturn mls.Sp_GCN_GRU_B(gcn_args,activation = torch.nn.RReLU()).to(args.device)\n",
    "\t\telif args.model == 'egcn':\n",
    "\t\t\treturn egcn.EGCN(gcn_args, activation = torch.nn.RReLU()).to(args.device)\n",
    "\t\telif args.model == 'egcn_h':\n",
    "\t\t\treturn egcn_h.EGCN(gcn_args, activation = torch.nn.RReLU(), device = args.device)\n",
    "\t\telif args.model == 'skipfeatsegcn_h':\n",
    "\t\t\treturn egcn_h.EGCN(gcn_args, activation = torch.nn.RReLU(), device = args.device, skipfeats=True)\n",
    "\t\telif args.model == 'egcn_o':\n",
    "\t\t\treturn egcn_o.EGCN(gcn_args, activation = torch.nn.RReLU(), device = args.device)\n",
    "\t\telse:\n",
    "\t\t\traise NotImplementedError('need to finish modifying the models')\n",
    "\n",
    "def build_classifier(args,tasker):\n",
    "\tif 'node_cls' == args.task or 'static_node_cls' == args.task:\n",
    "\t\tmult = 1\n",
    "\telse:\n",
    "\t\tmult = 2\n",
    "\tif 'gru' in args.model or 'lstm' in args.model:\n",
    "\t\tin_feats = args.gcn_parameters['lstm_l2_feats'] * mult\n",
    "\telif args.model == 'skipfeatsgcn' or args.model == 'skipfeatsegcn_h':\n",
    "\t\tin_feats = (args.gcn_parameters['layer_2_feats'] + args.gcn_parameters['feats_per_node']) * mult\n",
    "\telse:\n",
    "\t\tin_feats = args.gcn_parameters['layer_2_feats'] * mult\n",
    "\n",
    "\treturn mls.Classifier(args,in_features = in_feats, out_features = tasker.num_classes).to(args.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--config_file CONFIG_FILE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/gimpuleumoe/Library/Jupyter/runtime/kernel-0c270a1f-f8d9-4046-989c-a73ed0d725b3.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "parser = u.create_parser()\n",
    "args = u.parse_args(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "global rank, wsize, use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use CUDA: False - device: cpu\n",
      "MPI backend not preset. Set process rank to 0 (out of 1)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-a2a6954474bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Assign the requested random hyper parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_random_hyper_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m#build the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "use_cuda = (torch.cuda.is_available() and use_cuda)\n",
    "device='cpu'\n",
    "if use_cuda:\n",
    "    device='cuda'\n",
    "print (\"use CUDA:\", use_cuda, \"- device:\", device)\n",
    "try:\n",
    "    dist.init_process_group(backend='mpi') #, world_size=4\n",
    "    rank = dist.get_rank()\n",
    "    wsize = dist.get_world_size()\n",
    "    print('Hello from process {} (out of {})'.format(dist.get_rank(), dist.get_world_size()))\n",
    "    if use_cuda:\n",
    "        torch.cuda.set_device(rank )  # are we sure of the rank+1????\n",
    "        print('using the device {}'.format(torch.cuda.current_device()))\n",
    "except:\n",
    "    rank = 0\n",
    "    wsize = 1\n",
    "    print(('MPI backend not preset. Set process rank to {} (out of {})'.format(rank,\n",
    "                                                                               wsize)))\n",
    "\n",
    "if seed is None and seed!='None':\n",
    "    seed = 123+rank#int(time.time())+rank\n",
    "else:\n",
    "    seed=seed#+rank\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "seed=seed\n",
    "rank=rank\n",
    "wsize=wsize\n",
    "\n",
    "# Assign the requested random hyper parameters\n",
    "args = build_random_hyper_params(args)\n",
    "\n",
    "#build the dataset\n",
    "dataset = build_dataset(args)\n",
    "#build the tasker\n",
    "tasker = build_tasker(args,dataset)\n",
    "#build the splitter\n",
    "splitter = sp.splitter(args,tasker)\n",
    "#build the models\n",
    "gcn = build_gcn(args, tasker)\n",
    "classifier = build_classifier(args,tasker)\n",
    "\n",
    "#gcn.state_dict()\n",
    "#build a loss\n",
    "cross_entropy = ce.Cross_Entropy(args,dataset).to(device)\n",
    "\n",
    "#trainer\n",
    "trainer = tr.Trainer(args,\n",
    "                     splitter = splitter,\n",
    "                     gcn = gcn,\n",
    "                     classifier = classifier,\n",
    "                     comp_loss = cross_entropy,\n",
    "                     dataset = dataset,\n",
    "                     num_classes = tasker.num_classes)\n",
    "best_eval, best_embs, pred_list, idx_list  = trainer.train()\n",
    "save_object(best_eval, 'pkl/best_eval.pkl')\n",
    "save_object(best_embs, 'pkl/best_embs.pkl')\n",
    "save_object(pred_list, 'pkl/pred_list.pkl')\n",
    "save_object(idx_list, 'pkl/idx_list.pkl')\n",
    "print(best_eval)\n",
    "#\tprint(best_embs.shape)\n",
    "#\tprint(best_embs)\n",
    "#\tprint(np.array(pred_list[-1]).shape)\n",
    "#print(pred_list[-1])\n",
    "#\tpd.DataFrame(pred_list[-1]).to_csv(\"pred.csv\")\n",
    "\n",
    "#\ttrainer.gcn.state_dict()\n",
    "#trainer.save_checkpoint(trainer.state_dict(), 'test.test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
