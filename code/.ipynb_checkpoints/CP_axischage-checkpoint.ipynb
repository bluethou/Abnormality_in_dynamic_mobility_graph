{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/bluethou/Documents/TUM2020S/Thesis2020/2020-pooreumoe-msc-thesis/code'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import FactorAnalysis, PCA\n",
    "import tensortools as tt\n",
    "from tensortools.operations import unfold as tt_unfold, khatri_rao\n",
    "import tensorly as tl\n",
    "from tensorly import unfold as tl_unfold\n",
    "from tensorly.decomposition import parafac\n",
    "\n",
    "# import some useful functions (they are available in utils.py)\n",
    "# from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tensor\n",
    "with open('global_daily_tensor.pkl', 'rb') as f:\n",
    "    travel_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(travel_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create serial tensors by slicing the time interval.\n",
    "W = 7 # window size\n",
    "serial_tensors = []\n",
    "for i in range(len(travel_data)-W):\n",
    "    if i%7 ==0: # to obtain mutually exclusive tensors\n",
    "        temp = np.swapaxes(travel_data[i:i+5],0,1)\n",
    "        travel_NFT = np.swapaxes(temp, 1,2)\n",
    "        serial_tensors.append(travel_NFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # without axis change\n",
    "# W = 5 # window size\n",
    "# serial_tensors = []\n",
    "# for i in range(len(travel_data)-W):\n",
    "#     serial_tensors.append(travel_data[i:i+5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(226, 452, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp = np.swapaxes(serial_tensors[0], 0,1)\n",
    "# travel_NFT = np.swapaxes(temp, 1,2)\n",
    "# travel_NFT.shape\n",
    "print(serial_tensors[0][:,:,1])\n",
    "print(\"----\")\n",
    "# print(tl.unfold(serial_tensors[0], mode=0).T)\n",
    "serial_tensors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interation: 0 | Loss (A): 0.002330947909465501 | Loss (C): 0.0023402655725602724\n",
      "interation: 9 | Loss (A): 0.0035067939343055477 | Loss (C): 0.003507189536336362\n",
      "interation: 18 | Loss (A): 0.003920909885454556 | Loss (C): 0.003949567487520175\n",
      "interation: 27 | Loss (A): 0.004795971635696656 | Loss (C): 0.004809367577905511\n",
      "interation: 36 | Loss (A): 0.005125723156928803 | Loss (C): 0.005146197767346547\n",
      "interation: 45 | Loss (A): 0.005089637992914361 | Loss (C): 0.005087474794660601\n",
      "interation: 54 | Loss (A): 0.004482297339425375 | Loss (C): 0.004484233257078011\n",
      "interation: 63 | Loss (A): 0.003405092665121511 | Loss (C): 0.0034019618985001556\n",
      "interation: 72 | Loss (A): 0.0010259525157242215 | Loss (C): 0.0010259943684331804\n",
      "interation: 81 | Loss (A): 0.0011642968252908196 | Loss (C): 0.0011629034631833435\n",
      "interation: 90 | Loss (A): 0.0012088772299777835 | Loss (C): 0.001208441919195607\n",
      "Average Loss of A:  0.003550452455815171 Average Loss of C 0.0035556933854504875\n"
     ]
    }
   ],
   "source": [
    "rank =5\n",
    "\n",
    "A = np.random.random((serial_tensors[0].shape[0], rank)) # N node\n",
    "B = np.random.random((serial_tensors[0].shape[1], rank)) # F feature\n",
    "C = np.random.random((serial_tensors[0].shape[2], rank)) # T time\n",
    "\n",
    "A_array = []\n",
    "C_array = []\n",
    "Ct_B =0\n",
    "B_At =0\n",
    "alpha = 0.05\n",
    "beta = 0.05\n",
    "T_interval = len(serial_tensors)\n",
    "\n",
    "res_a_sum = 0\n",
    "res_c_sum = 0\n",
    "\n",
    "for t in range(T_interval):\n",
    "  # optimiza A\n",
    "    Ct_B = khatri_rao([C, B])\n",
    "    Xt_mode1_transpose = tl.unfold(serial_tensors[t], mode=0).T\n",
    "    X = np.concatenate((Xt_mode1_transpose, np.sqrt(alpha)*A.T), axis=0)\n",
    "    I = np.identity(A.shape[1])\n",
    "    F = np.concatenate((Ct_B, np.sqrt(alpha)*I))\n",
    "    A = np.linalg.lstsq(F,X, rcond=None)[0].T\n",
    "    A_array.append(A)\n",
    "\n",
    "    # optimize C\n",
    "    B_At = khatri_rao([B, A])\n",
    "    Xt_mode3_transpose = tl.unfold(serial_tensors[t], mode=2).T\n",
    "    X = np.concatenate((Xt_mode3_transpose, np.sqrt(beta)*C.T), axis=0)\n",
    "    I = np.identity(C.shape[1])\n",
    "    F = np.concatenate((B_At, np.sqrt(beta)*I))\n",
    "    C = np.linalg.lstsq(F,X, rcond=None)[0].T\n",
    "    C_array.append(C)\n",
    "\n",
    "    res_a = np.square(Ct_B.dot(A.T) - Xt_mode1_transpose)\n",
    "    res_c = np.square(B_At.dot(C.T) - Xt_mode3_transpose)\n",
    "    res_a_sum += res_a.mean()\n",
    "    res_c_sum += res_c.mean()\n",
    "    \n",
    "    if t % int(T_interval * .1) == 0:\n",
    "        print(\"interation:\", t, \"| Loss (A):\", res_a.mean(), \"| Loss (C):\", res_c.mean())\n",
    "        \n",
    "print(\"Average Loss of A: \",res_a_sum/len(A_array), \"Average Loss of C\",res_c_sum/len(C_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize B\n",
    "# X = np.concatenate(, axis=0)\n",
    "X_concat = tl.unfold(serial_tensors[0], mode=1).T\n",
    "for x in range(len(serial_tensors)):\n",
    "    if x>0:\n",
    "        XtT_unfold = tl.unfold(serial_tensors[x], mode=1).T\n",
    "        X_concat = np.concatenate((X_concat, XtT_unfold))\n",
    "\n",
    "F_concat = khatri_rao([C_array[0], A_array[0]])\n",
    "for i in range(len(C_array)):\n",
    "    if i >0:\n",
    "        F_concat = np.concatenate((F_concat, khatri_rao([C_array[i], A_array[i]])))\n",
    "        \n",
    "B = np.linalg.lstsq(F_concat,X_concat, rcond=None)[0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_a = np.square(khatri_rao([C, B]).dot(A.T) - Xt_mode1_transpose)\n",
    "# res_c = np.square(khatri_rao([B, A]).dot(C.T) - Xt_mode3_transpose)\n",
    "# print(res_a.mean(), res_c.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss of A:  0.0008294691062817705 Average Loss of C 0.0008297403638795831\n"
     ]
    }
   ],
   "source": [
    "# Adjusted error measure\n",
    "res_a_sum = 0\n",
    "res_c_sum = 0\n",
    "\n",
    "for i in range(len(A_array)):\n",
    "    Ai = A_array[i]\n",
    "    Ci = C_array[i]\n",
    "    res_a_sum += np.square(khatri_rao([Ci, B]).dot(Ai.T) - Xt_mode1_transpose).mean()\n",
    "    res_c_sum += np.square(khatri_rao([B, Ai]).dot(Ci.T) - Xt_mode3_transpose).mean()\n",
    "\n",
    "print(\"Average Loss of A: \",res_a_sum/len(A_array), \"Average Loss of C\",res_c_sum/len(C_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "B_old =copy.deepcopy(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interation: 0 | Loss (A): 0.0023273527398437093 | Loss (C): 0.002338578568980884\n",
      "interation: 9 | Loss (A): 0.00348694342573194 | Loss (C): 0.0034936756140144225\n",
      "interation: 18 | Loss (A): 0.003958103628542142 | Loss (C): 0.003943355941484641\n",
      "interation: 27 | Loss (A): 0.004806933038201584 | Loss (C): 0.004811460636647427\n",
      "interation: 36 | Loss (A): 0.005169700109156614 | Loss (C): 0.005131361231717314\n",
      "interation: 45 | Loss (A): 0.005088105607121537 | Loss (C): 0.0050997861076756525\n",
      "interation: 54 | Loss (A): 0.004504269027323816 | Loss (C): 0.004495554732001259\n",
      "interation: 63 | Loss (A): 0.0034165197918697115 | Loss (C): 0.0033916138517795383\n",
      "interation: 72 | Loss (A): 0.0010260616899027018 | Loss (C): 0.0010273467795059988\n",
      "interation: 81 | Loss (A): 0.001162149193721454 | Loss (C): 0.001163023862816482\n",
      "interation: 90 | Loss (A): 0.0012081603530538641 | Loss (C): 0.001210302883139687\n",
      "Average Loss of A:  0.0035526269743835714 Average Loss of C 0.0035565890970770744\n"
     ]
    }
   ],
   "source": [
    "# Re-optimize A & C \n",
    "rank =5\n",
    "\n",
    "A = A_array[0] # N node\n",
    "# B = np.random.random((serial_tensors[0].shape[1], rank)) # F feature\n",
    "C = C_array[0] # T time\n",
    "\n",
    "Aopt_array = []\n",
    "Copt_array = []\n",
    "Ct_B =0\n",
    "B_At =0\n",
    "alpha = 0.05\n",
    "beta = 0.05\n",
    "T_interval = len(serial_tensors)\n",
    "\n",
    "res_a_sum = 0\n",
    "res_c_sum = 0\n",
    "\n",
    "for t in range(T_interval):\n",
    "  # optimiza A\n",
    "    Ct_B = khatri_rao([C, B])\n",
    "    Xt_mode1_transpose = tl.unfold(serial_tensors[t], mode=0).T\n",
    "    X = np.concatenate((Xt_mode1_transpose, np.sqrt(alpha)*A.T), axis=0)\n",
    "    I = np.identity(A.shape[1])\n",
    "    F = np.concatenate((Ct_B, np.sqrt(alpha)*I))\n",
    "    A = np.linalg.lstsq(F,X, rcond=None)[0].T\n",
    "    Aopt_array.append(A)\n",
    "\n",
    "    # optimize C\n",
    "    B_At = khatri_rao([B, A])\n",
    "    Xt_mode3_transpose = tl.unfold(serial_tensors[t], mode=2).T\n",
    "    X = np.concatenate((Xt_mode3_transpose, np.sqrt(beta)*C.T), axis=0)\n",
    "    I = np.identity(C.shape[1])\n",
    "    F = np.concatenate((B_At, np.sqrt(beta)*I))\n",
    "    C = np.linalg.lstsq(F,X, rcond=None)[0].T\n",
    "    Copt_array.append(C)\n",
    "\n",
    "    res_a = np.square(Ct_B.dot(A.T) - Xt_mode1_transpose)\n",
    "    res_c = np.square(B_At.dot(C.T) - Xt_mode3_transpose)\n",
    "    res_a_sum += res_a.mean()\n",
    "    res_c_sum += res_c.mean()\n",
    "    \n",
    "    if t % int(T_interval * .1) == 0:\n",
    "        print(\"interation:\", t, \"| Loss (A):\", res_a.mean(), \"| Loss (C):\", res_c.mean())\n",
    "        \n",
    "print(\"Average Loss of A: \",res_a_sum/len(A_array), \"Average Loss of C\",res_c_sum/len(C_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Re-optimize B\n",
    "# # X = np.concatenate(, axis=0)\n",
    "# X_concat = tl.unfold(serial_tensors[0], mode=1).T\n",
    "# for x in range(len(serial_tensors)):\n",
    "#     if x>0:\n",
    "#         XtT_unfold = tl.unfold(serial_tensors[x], mode=1).T\n",
    "#         X_concat = np.concatenate((X_concat, XtT_unfold))\n",
    "\n",
    "# F_concat = khatri_rao([Copt_array[0], Aopt_array[0]])\n",
    "# for i in range(len(C_array)):\n",
    "#     if i >0:\n",
    "#         F_concat = np.concatenate((F_concat, khatri_rao([Copt_array[i], Aopt_array[i]])))\n",
    "        \n",
    "# B = np.linalg.lstsq(F_concat,X_concat, rcond=None)[0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss of A:  0.0008392913581987916 Average Loss of C 0.0008393501444858161\n"
     ]
    }
   ],
   "source": [
    "# Adjusted error measure\n",
    "res_a_sum = 0\n",
    "res_c_sum = 0\n",
    "\n",
    "for i in range(len(A_array)):\n",
    "    Ai = Aopt_array[i]\n",
    "    Ci = Copt_array[i]\n",
    "    res_a_sum += np.square(khatri_rao([Ci, B]).dot(Ai.T) - Xt_mode1_transpose).mean()\n",
    "    res_c_sum += np.square(khatri_rao([B, Ai]).dot(Ci.T) - Xt_mode3_transpose).mean()\n",
    "\n",
    "print(\"Average Loss of A: \",res_a_sum/len(A_array), \"Average Loss of C\",res_c_sum/len(C_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "# os.chdir('/Users/bluethou/Thesis2020/thesis_pooreumoe_kim/code')\n",
    "os.getcwd()\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "save_object(Aopt_array, 'Aopt_daily.pkl')\n",
    "save_object(Copt_array, 'Copt_daily.pkl')\n",
    "save_object(B, 'Bstar_daily.pkl')\n",
    "# pickle.dump(tensor, file = open(\"travel_tensor.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006894491806455055 0.0006870834315116902\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-64c95f778175>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mres_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCt_B\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mXt_mode1_transpose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mres_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB_At\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mXt_mode3_transpose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;31m# optimize B\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# New Algorithm - meaning less\n",
    "rank =5\n",
    "\n",
    "A = np.random.random((serial_tensors[0].shape[0], rank)) # N node\n",
    "B = np.random.random((serial_tensors[0].shape[1], rank)) # F feature\n",
    "C = np.random.random((serial_tensors[0].shape[2], rank)) # T time\n",
    "\n",
    "for iter in range(10):\n",
    "    A_array = []\n",
    "    C_array = []\n",
    "    Ct_B =0\n",
    "    B_At =0\n",
    "    alpha = 0.001\n",
    "    beta = 0.001\n",
    "    T_interval = len(serial_tensors)\n",
    "\n",
    "#     res_a_sum = 0\n",
    "#     res_c_sum = 0\n",
    "\n",
    "    for t in range(T_interval):\n",
    "      # optimiza A\n",
    "        Ct_B = khatri_rao([C, B])\n",
    "        Xt_mode1_transpose = tl.unfold(serial_tensors[t], mode=0).T\n",
    "        X = np.concatenate((Xt_mode1_transpose, np.sqrt(alpha)*A.T), axis=0)\n",
    "        I = np.identity(A.shape[1])\n",
    "        F = np.concatenate((Ct_B, np.sqrt(alpha)*I))\n",
    "        A = np.linalg.lstsq(F,X, rcond=None)[0].T\n",
    "        A_array.append(A)\n",
    "\n",
    "        # optimize C\n",
    "        B_At = khatri_rao([B, A])\n",
    "        Xt_mode3_transpose = tl.unfold(serial_tensors[t], mode=2).T\n",
    "        X = np.concatenate((Xt_mode3_transpose, np.sqrt(beta)*C.T), axis=0)\n",
    "        I = np.identity(C.shape[1])\n",
    "        F = np.concatenate((B_At, np.sqrt(beta)*I))\n",
    "        C = np.linalg.lstsq(F,X, rcond=None)[0].T\n",
    "        C_array.append(C)\n",
    "\n",
    "        res_a = np.square(Ct_B.dot(A.T) - Xt_mode1_transpose)\n",
    "        res_c = np.square(B_At.dot(C.T) - Xt_mode3_transpose)\n",
    "    \n",
    "    # optimize B\n",
    "    X_concat = tl.unfold(serial_tensors[0], mode=1).T\n",
    "    for x in range(len(serial_tensors)):\n",
    "        if x>0:\n",
    "            XtT_unfold = tl.unfold(serial_tensors[x], mode=1).T\n",
    "            X_concat = np.concatenate((X_concat, XtT_unfold))\n",
    "\n",
    "    F_concat = khatri_rao([C_array[0], A_array[0]])\n",
    "    for i in range(len(C_array)):\n",
    "        if i >0:\n",
    "            F_concat = np.concatenate((F_concat, khatri_rao([C_array[i], A_array[i]])))\n",
    "\n",
    "    B = np.linalg.lstsq(F_concat,X_concat, rcond=None)[0].T\n",
    "\n",
    "    # Adjusted error measure\n",
    "    res_a_sum = 0\n",
    "    res_c_sum = 0\n",
    "    for i in range(len(A_array)):\n",
    "        Ai = A_array[i]\n",
    "        Ci = C_array[i]\n",
    "        res_a_sum += np.square(khatri_rao([Ci, B]).dot(Ai.T) - Xt_mode1_transpose).mean()\n",
    "        res_c_sum += np.square(khatri_rao([B, Ai]).dot(Ci.T) - Xt_mode3_transpose).mean()\n",
    "    print(res_a_sum/len(A_array), res_c_sum/len(C_array))\n",
    "    \n",
    "    # New initialization for the next loop\n",
    "    A = A_array[0] \n",
    "    C = C_array[0]\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
