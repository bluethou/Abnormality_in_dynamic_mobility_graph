{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../pkl/global_Aopt_array.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-77bf18229434>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../pkl/global_Aopt_array.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mAopt_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../pkl/global_Aopt_array.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# Load data\n",
    "with open('../pkl/global_Aopt_array.pkl', 'rb') as f:\n",
    "    Aopt_array = pickle.load(f)\n",
    "\n",
    "with open('../pkl/global_Copt_array.pkl', 'rb') as f:\n",
    "    Copt_array = pickle.load(f)\n",
    "    \n",
    "with open('../pkl/global_Bstar.pkl', 'rb') as f:\n",
    "    Bstar = pickle.load(f)\n",
    "    \n",
    "with open('../pkl/global_travel_tensor.pkl', 'rb') as f:\n",
    "    travel_tensor = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_slices = pd.date_range('2016-01-04', periods=200, freq='W')\n",
    "tensor_slices = []\n",
    "for i in range(len(week_slices)):\n",
    "    if i % 4 == 0 :\n",
    "        tensor_slices.append(week_slices[i].date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_df = pd.read_csv('../csv/global_travel_df.csv')\n",
    "countries = travel_df['node'].unique().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(np.exp(Aopt_array))[:,3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.array(np.exp(Aopt_array))[:,0,:]\n",
    "# clf = LocalOutlierFactor(n_neighbors=10, contamination=0.1)\n",
    "# clf.fit(X)\n",
    "# neg_scores = clf.negative_outlier_factor_\n",
    "# lof_scores = (np.max(neg_scores) - neg_scores)/(np.max(neg_scores) - np.min(neg_scores))\n",
    "# # print(lof_scores)\n",
    "# plt.scatter(tensor_slices[0:-1],lof_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOF_by_countries = []\n",
    "for i in range(Aopt_array[0].shape[0]):\n",
    "#     X = np.array(np.exp(Aopt_array))[:,i,:]\n",
    "    X = np.array(Aopt_array)[:,i,:]\n",
    "    clf = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
    "    clf.fit(X)\n",
    "    neg_scores = clf.negative_outlier_factor_\n",
    "#     lof_scores = (np.max(neg_scores) - neg_scores)/(np.max(neg_scores) - np.min(neg_scores))\n",
    "    lof_scores = neg_scores * -1\n",
    "    LOF_by_countries.append(lof_scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.array(Aopt_array)[:,i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12,12])\n",
    "plt.subplot(5, 1, 1)\n",
    "plt.scatter(tensor_slices[0:-1],LOF_by_countries[0])\n",
    "plt.title('LOF score of ' + countries[0])\n",
    "# plt.title('LOF score of Germany')\n",
    "\n",
    "plt.subplot(5, 1, 2)\n",
    "plt.scatter(tensor_slices[0:-1],LOF_by_countries[3])\n",
    "# plt.title('LOF score of Italy')\n",
    "plt.title('LOF score of ' + countries[3])\n",
    "\n",
    "plt.subplot(5, 1, 3)\n",
    "plt.scatter(tensor_slices[0:-1],LOF_by_countries[4])\n",
    "# plt.title('LOF score of United Kingdom')\n",
    "plt.title('LOF score of ' + countries[4])\n",
    "\n",
    "plt.subplot(5, 1, 4)\n",
    "plt.scatter(tensor_slices[0:-1],LOF_by_countries[5])\n",
    "# plt.title('LOF score of France')\n",
    "plt.title('LOF score of ' + countries[5])\n",
    "\n",
    "plt.subplot(5, 1, 5)\n",
    "plt.scatter(tensor_slices[0:-1],LOF_by_countries[40])\n",
    "# plt.title('LOF score of Spain')\n",
    "plt.title('LOF score of ' + countries[40])\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.savefig(\"global_LOF_with_seasonality.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2018\n",
    "June\n",
    "In the UK it will be a year since a van and gun attack was launched in central London - eight people were killed. The slaughter at Borough Market had come just weeks after 22 people were left dead by a bombing after a pop concert at Manchester Arena.\n",
    "https://www.euronews.com/2018/01/01/what-are-the-key-events-to-look-out-for-in-europe-in-2018-\n",
    "\n",
    "August\n",
    "It’s a year this month since a group of 12 jihadists launched a series of attacks in and around the Spanish city of Barcelona.\n",
    "Sixteen people were killed as a result of the violence, including 14 on the Catalan capital’s famous Las Ramblas boulevard.\n",
    "\n",
    "Later in August it’s half a century since Soviet troops invaded what was then Czechoslovakia to put down the countries brief period of political liberalisation - known as the Prague Spring.\n",
    "\n",
    "2017 France: Google Trned\n",
    "https://trends.google.co.kr/trends/explore?date=2017-01-01%202017-12-31&q=france\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series Analysis\n",
    "# According to GR, the amount of travel data increase linearly since 2014\n",
    "# Thus we first start differencing to remove this trend\n",
    "LOF_DE = LOF_by_countries[5]\n",
    "\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn diff\n",
    " \n",
    "# invert differenced forecast\n",
    "def inverse_difference(last_ob, value):\n",
    "\treturn value + last_ob\n",
    "\n",
    "LOF_dif = difference(LOF_DE)\n",
    "# len(LOF_dif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cont_num = 18\n",
    "LOF_DE = LOF_by_countries[cont_num]\n",
    "LOF_dif = difference(LOF_DE)\n",
    "inverted = [inverse_difference(LOF_DE[i], LOF_dif[i]) for i in range(len(LOF_dif))]\n",
    "# print(inverted)\n",
    "\n",
    "plt.figure(figsize=[12,4])\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.scatter(tensor_slices[0:-2],inverted)\n",
    "plt.title('LOF score of '+ countries[cont_num])\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.scatter(range(0,len(tensor_slices[0:-2])),LOF_dif)\n",
    "x = range(0,len(tensor_slices[0:-2]))\n",
    "y = LOF_dif\n",
    "z = np.polyfit(x, y, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(x,p(x),\"r--\")\n",
    "plt.title('differenced LOF score of '+ countries[cont_num])\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "# plt.savefig(\"Linear_trend.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(p(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore LOF variance by time\n",
    "LOF_mat=np.array(LOF_by_countries[0:150])\n",
    "mean_array = np.mean(LOF_mat, axis=0) # mean by time.\n",
    "np.var(LOF_mat[:,40])\n",
    "std_array = np.sqrt(np.diag(np.cov(LOF_mat.T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12,12])\n",
    "country_num = 40\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.scatter(tensor_slices[0:-1], LOF_by_countries[country_num])\n",
    "plt.title('LOF score of '+ countries[country_num])\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.scatter(tensor_slices[0:-1], np.divide(mean_array,std_array))\n",
    "# plt.scatter(tensor_slices[0:-1], std_array)\n",
    "plt.title('Global average LOF')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.scatter(tensor_slices[0:-1], np.divide(LOF_by_countries[country_num]-mean_array, std_array))\n",
    "plt.title('normalized LOF score of '+ countries[country_num])\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOF_mat[:,:-1].shape\n",
    "LOF_mat[:,1:].shape\n",
    "diff_mat = LOF_mat[:,1:] - LOF_mat[:,:-1]\n",
    "diff_var = np.diag(np.cov(diff_mat.T))\n",
    "# plt.scatter(range(0,40),difference(LOF_by_countries[2])/np.sqrt(diff_var))\n",
    "# plt.scatter(range(0,40), np.sqrt(diff_var))\n",
    "plt.scatter(range(0,len(tensor_slices[0:-2])), difference(LOF_by_countries[10]))\n",
    "# plt.scatter(range(0,len(tensor_slices[0:-2])), np.log(np.array(LOF_dif)+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('global_travel_tensor.pkl', 'rb') as f:\n",
    "    travel_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tensor_slices[0:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "country_num = 4\n",
    "X2=travel_tensor[:,country_num,:]\n",
    "diff_travel = difference(np.sum(X2, axis=1))\n",
    "\n",
    "clf = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
    "clf.fit(X2)\n",
    "neg_scores = clf.negative_outlier_factor_\n",
    "lof_scores = neg_scores * -1\n",
    "\n",
    "plt.figure(figsize=[12,12])\n",
    "plt.subplot(3, 1, 1)\n",
    "# plt.scatter(week_slices, np.sum(X2, axis=1))\n",
    "plt.plot(week_slices[:], (np.sum(X2, axis=1)))\n",
    "plt.title('Raw travel traffic of South Korea')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "# plt.scatter(week_slices[1:], difference(lof_scores)).\n",
    "plt.scatter(tensor_slices[:-1], LOF_by_countries[country_num])\n",
    "plt.title('LOF scores by TBAD of South Korea')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.scatter(tensor_slices[1:-1], difference(LOF_by_countries[country_num]))\n",
    "# plt.scatter(tensor_slices[:-1], LOF_by_countries[country_num])\n",
    "plt.title('Differenced LOF scores by TBAD of South Korea')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.savefig(\"LOF_evaluation.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = np.abs(difference(LOF_by_countries[country_num]))>0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transport matrix visualization\n",
    "tensor_slices[-8] # datetime.date(2018, 8, 19)\n",
    "# print(travel_data[-8,:,0:75])\n",
    "plt.matshow(travel_data[-6,0:5,0:75])\n",
    "plt.matshow(travel_data[-7,0:5,0:75])\n",
    "plt.matshow(travel_data[-8,0:5,0:75])\n",
    "plt.matshow(travel_data[-9,0:5,0:75])\n",
    "plt.matshow(travel_data[-10,0:5,0:75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Aopt_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A(t) visualization\n",
    "plt.figure(figsize=[18,5])\n",
    "# plt.subplot(5, 1, 1)\n",
    "# plt.figure(figsize=(10,5))\n",
    "# plt.matshow(Aopt_array[1].T, fignum=1, aspect='auto')\n",
    "# plt.matshow(Aopt_array[10].T, fignum=2, aspect='auto')\n",
    "# plt.matshow(Aopt_array[20].T, fignum=3, aspect='auto')\n",
    "# plt.matshow(Aopt_array[30].T, fignum=4, aspect='auto')\n",
    "# plt.matshow(Aopt_array[40].T, fignum=5, aspect='auto')\n",
    "\n",
    "plt.contourf(Aopt_array[1].T); plt.colorbar()\n",
    "# plt.contourf(Aopt_array[40].T)\n",
    "# plt.contourf(Aopt_array[20].T, fignum = 3); plt.colorbar()\n",
    "# plt.contourf(Aopt_array[30].T, fignum = 4); plt.colorbar()\n",
    "# plt.contourf(Aopt_array[40].T, fignum = 5); plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,3))\n",
    "plt.contourf(Aopt_array[1].T)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
